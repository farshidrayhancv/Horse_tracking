# Video file path (required) - filename format: horse_XX.mp4 where XX = number of horses
video_path: inputs/horse_11.mp4  # Will automatically detect 22 horses + 22 jockeys

# Output settings
output_path: null  # Auto-generate if null (will include "_rgb_d_reid_tracked_" in filename)
display: false

# Model selection
human_detector: rtdetr
horse_detector: rtdetr  # Options: rtdetr, superanimal (NOT RECOMMENDED VERY SLOW), both
human_pose_estimator: vitpose
horse_pose_estimator: superanimal # Options: superanimal (better), vitpose, dual

# NEW: SAM model selection
sam_model: sam2  # Options: sam2 (latest Meta model, more accurate), mobilesam (faster), none (no segmentation)

# Separate confidence thresholds for each model
confidence_human_detection: 0.5
confidence_horse_detection: 0.5
confidence_human_pose: 0.5
confidence_horse_pose_superanimal: 0.5
confidence_horse_pose_vitpose: 0.5

# Tracking and jockey detection settings
jockey_overlap_threshold: 0.4

# Processing settings
max_frames: null
device: cuda

# Enhanced RGB-D Re-identification Pipeline Settings
enable_reid_pipeline: true
reid_similarity_threshold: 0.3  # Threshold for RGB-D feature matching
reid_embedding_history_size: 10  # Number of embeddings to store per track
enable_mobile_sam: true          # Keep for backward compatibility (now controlled by sam_model)
enable_depth_anything: true      # Enable Depth-Anything for depth estimation
enable_megadescriptor: true      # Enable MegaDescriptor for feature extraction

# RGB-D Fusion Settings (Advanced)
rgb_weight: 0.5                  # Weight for RGB features (0.0-1.0)
depth_weight: 0.5                # Weight for depth shape features (0.0-1.0)
depth_shape_consistency: true    # Enable depth shape consistency checking
consistency_bonus_threshold: 0.4 # Threshold for consistency bonus

# NOTE: Expected horse/jockey counts are automatically parsed from filename
# Examples:
#   horse_11.mp4 -> 11 horses, 11 jockeys
#   horse_22.mp4 -> 22 horses, 22 jockeys
#   horse_8.mp4  -> 8 horses, 8 jockeys

# SAM Model Comparison:
# - sam2: Meta's latest SAM model with improved accuracy and robustness
#   * More accurate segmentation, especially for challenging cases
#   * Better handles occlusions and complex backgrounds
#   * Requires more GPU memory and slightly slower
#   * Recommended for best quality results
#
# - mobilesam: Lightweight version optimized for speed
#   * Faster inference, lower memory usage
#   * Good for real-time applications or limited resources
#   * Slightly less accurate than SAM2
#
# - none: Disables segmentation entirely
#   * Uses simple bounding box crops only
#   * Fastest option but without precise object boundaries
#   * Good for testing or when segmentation is not critical

# RGB-D Re-ID Pipeline Overview:
# 1. Depth-Anything estimates full-image depth map
# 2. SAM (MobileSAM or SAM2) segments objects within bounding boxes
# 3. RGB and depth crops are extracted with segmentation masks
# 4. MegaDescriptor extracts features from both RGB and depth
# 5. Features are fused with weighted combination (70% RGB + 30% depth)
# 6. Depth shape statistics provide geometric consistency
# 7. Enhanced matching considers both appearance and shape similarity